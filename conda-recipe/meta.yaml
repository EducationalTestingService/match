{% set data = load_setup_py_data() %}

package:
  name: {{ data.get('name') }}
  version: {{ data.get('version') }}

source:
  git_url: {{ data.get('url') }}
  path: ../match

build:
  noarch: python
  script:
    - cd $SRC_DIR
    - "{{ PYTHON }} -m pip install . --no-deps -vv"

{% block requirements -%}
requirements:
  build:
    {% for req in data.get('install_requires', []) -%}
    - {{(req.replace(">", " >") if ">" in req else req.replace("==", " "))}}
    {% endfor %}
  run:
    - python
    {% for package in resolved_packages('build') -%}
    - {{ package }}
    {% endfor %}
{%- endblock %}

about:
  home: {{ data.get('url') }}
  license: Apache 2.0
  summary: Obtain offsets of tokenizer-standardized clean strings within messy text.